.catalog:
  name: "Logstash"
  version: "6.1.1-rancher1"
  description: "Logstash: Process Any Data, From Any Source"
  questions:
    - variable: "collector_inputs"
      description: |
        Logstash collection tier inputs. These will be added
        directly to input { } section of logstash.conf
      label: "Logstash inputs"
      type: "multiline"
      required: true
      default: |
        udp {
          type => "syslog"
          port => 5140
        }
        tcp {
          type => "syslog"
          port => 5140
        }
    - variable: "indexer_filters"
      description: |
        Logstash indexing tier filters. These will be added
        directly to filter { } section of logstash.conf
      label: "Logstash filters"
      type: "multiline"
      required: false
      default: |
        if [type] == "syslog" {
          if [host] =~ /10\.0\.110\.1/ {
            mutate {
              add_tag => ["PFSense", "Ready"]
            }
          }
        }
        if "Ready" not in [tags] {
          mutate {
            add_tag => [ "syslog" ]
          }
        }
        if [type] == "syslog" {
          mutate {
            remove_tag => "Ready"
          }
        if "syslog" in [tags] {
          grok {
            match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])? %{GREEDYDATA:syslog_message}" }
            add_field => [ "received_at", "%{@timestamp}" ]
            add_field => [ "received_from", "%{host}" ]
          }
        }
        syslog_pri { }
        date {
          match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM  dd HH:mm:ss" ]
          locale => "en"
        }
        if !("_grokparsefailure" in [tags]) {
          mutate {
            replace => [ "@source_host", "%{syslog_hostname}" ]
            replace => [ "@message", "%{syslog_message}" ]
          }
        }
        mutate {
          remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
        }
        if "PFSense" in [tags] {
          grok {
            add_tag => [ "firewall" ]
            match => [ "message", "<(?<evtid>.*)>(?<datetime>(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\s+(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) (?:2[0123]|[01]?[0-9]):(?:[0-5][0-9]):(?:[0-5][0-9])) (?<prog>.*?) (?<msg>.*)" ]
          }
          mutate {
            gsub => ["datetime","  "," "]
          }
          date {
            match => [ "datetime", "MMM dd HH:mm:ss" ]
          }
          mutate {
            replace => [ "message", "%{msg}" ]
          }
          mutate {
            remove_field => [ "msg", "datetime" ]
          }
        }
    - variable: "indexer_outputs"
      description: |
        Logstash indexing tier outputs. These will be added
        directly to output { } section of logstash.conf
      label: "Logstash outputs"
      type: "multiline"
      required: true
      default: |
        elasticsearch {
          hosts => ["elasticsearch.rancher.internal:9200"]
        }
        stdout {
          codec => rubydebug
        }
    - variable: "elasticsearch_link"
      description: |
        stack/service link or external service link to elasticsearch
        cluster.
      label: "Elasticsearch stack/service"
      default: "es/elasticsearch-clients"
      required: true
      type: "service"
logstash-indexer:
  metadata:
    logstash:
      inputs: |
        redis {
          host => "redis.rancher.internal"
          port => "6379"
          data_type => "list"
          key => "logstash"
        }
      filters: |
        ${indexer_filters}
      outputs: |
        ${indexer_outputs}
logstash-collector:
  metadata:
    logstash:
      inputs: |
        ${collector_inputs}
      outputs: |
        redis {
          host => "redis.rancher.internal"
          port => "6379"
          data_type => "list"
          key => "logstash"
        }
